{
  "AppConfig": {
    "Models": [
      {
        "Id": "claude-3-sonnet",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "Anthropic",
            "supports_budget_tokens": true,
            "supports_thinking_type": true,
            "max_thinking_tokens": 8192,
            "is_built_in": false,
            "is_exposed": true,
            "parameter_name": "thinking"
          },
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 5242880,
            "max_images_per_message": 20
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": false,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 200000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 190000
          },
          "response_formats": {
            "supports_json_mode": false,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["thinking", "multimodal", "function-calling", "long-context"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:15",
            "tokens_per_second": 50.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Anthropic",
            "ModelName": "claude-3-sonnet-20240229",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 3.0,
              "CompletionPerMillion": 15.0
            },
            "Tags": ["high-quality", "thinking", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "anthropic/claude-3-sonnet",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 3.0,
              "CompletionPerMillion": 15.0
            },
            "SubProviders": [
              {
                "Name": "Anthropic",
                "ModelName": "claude-3-sonnet-20240229",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 3.0,
                  "CompletionPerMillion": 15.0
                }
              },
              {
                "Name": "AWS Bedrock",
                "ModelName": "anthropic.claude-3-sonnet-20240229-v1:0",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 3.0,
                  "CompletionPerMillion": 15.0
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "gpt-4o",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": true,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "supported_audio_formats": ["mp3", "wav", "m4a"],
            "max_image_size": 20971520,
            "max_images_per_message": 10
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 128,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 16384,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "structured-output"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:10",
            "tokens_per_second": 75.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "gpt-4o",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 2.5,
              "CompletionPerMillion": 10.0
            },
            "Tags": ["fast", "high-quality", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "openai/gpt-4o",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 2.5,
              "CompletionPerMillion": 10.0
            },
            "SubProviders": [
              {
                "Name": "OpenAI",
                "ModelName": "gpt-4o",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 2.5,
                  "CompletionPerMillion": 10.0
                }
              },
              {
                "Name": "Azure OpenAI",
                "ModelName": "gpt-4o",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 2.5,
                  "CompletionPerMillion": 10.0
                }
              },
              {
                "Name": "Together AI",
                "ModelName": "meta-llama/Llama-2-70b-chat-hf",
                "Priority": 3,
                "Pricing": {
                  "PromptPerMillion": 2.2,
                  "CompletionPerMillion": 9.5
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "openai/gpt-4o",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 2.2,
              "CompletionPerMillion": 9.0
            },
            "Tags": ["economic", "openai-compatible", "multi-vendor"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "meta-llama/llama-4-maverick:free",
            "Priority": 4,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "multimodal", "moe", "high-performance", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "gpt-4o-mini",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 20971520,
            "max_images_per_message": 10
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 128,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 16384,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "structured-output"],
          "performance": {
            "typical_latency": "00:00:01",
            "max_latency": "00:00:05",
            "tokens_per_second": 100.0,
            "quality_tier": "medium",
            "cost_tier": "economy"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "gpt-4o-mini",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 0.15,
              "CompletionPerMillion": 0.6
            },
            "Tags": ["fast", "economic", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "openai/gpt-4o-mini",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.15,
              "CompletionPerMillion": 0.6
            },
            "Tags": ["fallback", "economic", "reliable", "aggregator", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "openai/gpt-4o-mini",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.12,
              "CompletionPerMillion": 0.5
            },
            "Tags": ["economic", "cost-effective", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "o1-preview",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "OpenAI",
            "supports_budget_tokens": false,
            "supports_thinking_type": false,
            "is_built_in": true,
            "is_exposed": false
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 32768,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": false,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": false,
          "supported_features": ["reasoning", "complex-problem-solving"],
          "performance": {
            "typical_latency": "00:00:15",
            "max_latency": "00:01:00",
            "tokens_per_second": 10.0,
            "quality_tier": "premium"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "o1-preview",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 15.0,
              "CompletionPerMillion": 60.0
            },
            "Tags": ["reasoning", "premium", "complex-tasks"]
          }
        ]
      },
      {
        "Id": "llama-3.1-70b-instruct",
        "IsReasoning": false,
        "Capabilities": {
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 4096,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["function-calling", "open-source"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:08",
            "tokens_per_second": 80.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "llama3-70b-8192",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "Tags": ["ultra-fast", "high-performance", "open-source", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "meta-llama/Meta-Llama-3.1-70B-Instruct",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.52,
              "CompletionPerMillion": 0.75
            },
            "Tags": ["economic", "open-source", "openai-compatible", "multi-vendor"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "meta-llama/llama-3.1-70b-instruct",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "SubProviders": [
              {
                "Name": "Together AI",
                "ModelName": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 0.59,
                  "CompletionPerMillion": 0.79
                }
              },
              {
                "Name": "Fireworks AI",
                "ModelName": "accounts/fireworks/models/llama-v3p1-70b-instruct",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 0.54,
                  "CompletionPerMillion": 0.74
                }
              },
              {
                "Name": "Perplexity",
                "ModelName": "llama-3.1-70b-instruct",
                "Priority": 3,
                "Pricing": {
                  "PromptPerMillion": 0.52,
                  "CompletionPerMillion": 0.75
                }
              },
              {
                "Name": "Lepton AI",
                "ModelName": "llama3-1-70b",
                "Priority": 4,
                "Pricing": {
                  "PromptPerMillion": 0.50,
                  "CompletionPerMillion": 0.70
                }
              },
              {
                "Name": "OpenRouter Free",
                "ModelName": "meta-llama/llama-4-scout:free",
                "Priority": 5,
                "Pricing": {
                  "PromptPerMillion": 0.0,
                  "CompletionPerMillion": 0.0
                },
                "Tags": ["free"]
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "open-source", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "llama-4-scout-17b-16e-instruct",
        "IsReasoning": false,
        "Capabilities": {
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 131072,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["function-calling", "open-source"],
          "performance": {
            "typical_latency": "00:00:01",
            "max_latency": "00:00:05",
            "tokens_per_second": 120.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "meta-llama/llama-4-scout-17b-16e-instruct",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.2,
              "CompletionPerMillion": 0.2
            },
            "Tags": ["ultra-fast", "economic", "high-performance", "open-source", "openai-compatible"]
          },
          {
            "Name": "Cerebras",
            "ModelName": "llama-4-scout-17b-16e-instruct",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.1,
              "CompletionPerMillion": 0.1
            },
            "Tags": ["ultra-fast", "economic", "high-performance", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "gemini-2.0-flash",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": true,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "supported_audio_formats": ["mp3", "wav", "m4a"],
            "max_image_size": 20971520,
            "max_images_per_message": 16
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 1000000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 990000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "long-context", "structured-output"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:08",
            "tokens_per_second": 85.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "GoogleGemini",
            "ModelName": "gemini-2.0-flash",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.075,
              "CompletionPerMillion": 0.3
            },
            "Tags": ["economic", "multimodal", "fast", "long-context", "openai-compatible"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "google/gemini-2.0-flash",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.075,
              "CompletionPerMillion": 0.3
            },
            "SubProviders": [
              {
                "Name": "Google AI",
                "ModelName": "gemini-2.0-flash",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 0.075,
                  "CompletionPerMillion": 0.3
                }
              },
              {
                "Name": "Google Vertex AI",
                "ModelName": "gemini-2.0-flash",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 0.075,
                  "CompletionPerMillion": 0.3
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "multimodal", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "deepseek-r1-distill-llama-70b",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "DeepSeek",
            "supports_budget_tokens": false,
            "supports_thinking_type": false,
            "is_built_in": true,
            "is_exposed": true
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["reasoning", "function-calling"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:12",
            "tokens_per_second": 60.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "deepseek-r1-distill-llama-70b",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "Tags": ["ultra-fast", "reasoning", "thinking", "high-performance", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.52,
              "CompletionPerMillion": 0.75
            },
            "Tags": ["economic", "reasoning", "thinking", "openai-compatible", "multi-vendor"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "deepseek/deepseek-r1:free",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "reasoning", "thinking", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "deepseek-r1-free",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "DeepSeek",
            "supports_budget_tokens": false,
            "supports_thinking_type": false,
            "is_built_in": true,
            "is_exposed": true
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 163840,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 155000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["reasoning", "function-calling"],
          "performance": {
            "typical_latency": "00:00:05",
            "max_latency": "00:00:20",
            "tokens_per_second": 40.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "deepseek/deepseek-r1:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "reasoning", "thinking", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "llama-4-maverick-free",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 20971520,
            "max_images_per_message": 16
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 256000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 245000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "moe-architecture"],
          "performance": {
            "typical_latency": "00:00:04",
            "max_latency": "00:00:15",
            "tokens_per_second": 70.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "meta-llama/llama-4-maverick:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "multimodal", "moe", "high-performance", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "llama-4-scout-free",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 20971520,
            "max_images_per_message": 16
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 512000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 500000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "long-context", "moe-architecture"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:12",
            "tokens_per_second": 85.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "meta-llama/llama-4-scout:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "multimodal", "long-context", "moe", "high-performance", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "gemini-2.5-pro-exp-free",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": true,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "supported_audio_formats": ["mp3", "wav", "m4a"],
            "max_image_size": 20971520,
            "max_images_per_message": 16
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 1000000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 990000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "long-context", "experimental"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:10",
            "tokens_per_second": 80.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "google/gemini-2.5-pro-exp-03-25:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "multimodal", "long-context", "experimental", "high-performance", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "qwen3-30b-a3b-free",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "Custom",
            "supports_budget_tokens": false,
            "supports_thinking_type": true,
            "is_built_in": true,
            "is_exposed": true
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 40960,
            "max_output_tokens": 4096,
            "recommended_max_prompt_tokens": 36000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["reasoning", "function-calling", "moe-architecture", "multilingual"],
          "performance": {
            "typical_latency": "00:00:04",
            "max_latency": "00:00:15",
            "tokens_per_second": 60.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "qwen/qwen3-30b-a3b:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "reasoning", "thinking", "moe", "multilingual", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "mistral-small-3.1-24b-free",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 10485760,
            "max_images_per_message": 8
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 96000,
            "max_output_tokens": 4096,
            "recommended_max_prompt_tokens": 90000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "json-mode"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:08",
            "tokens_per_second": 90.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "mistralai/mistral-small-3.1-24b-instruct:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "multimodal", "function-calling", "fast", "openai-compatible", "aggregator"]
          }
        ]
      },
      {
        "Id": "qwen3-0.6b-free",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "Custom",
            "supports_budget_tokens": false,
            "supports_thinking_type": true,
            "is_built_in": true,
            "is_exposed": true
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": false,
            "supports_tool_choice": true,
            "max_tools_per_request": 16,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 32000,
            "max_output_tokens": 2048,
            "recommended_max_prompt_tokens": 28000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["reasoning", "function-calling", "lightweight", "multilingual"],
          "performance": {
            "typical_latency": "00:00:01",
            "max_latency": "00:00:05",
            "tokens_per_second": 150.0,
            "quality_tier": "medium"
          }
        },
        "Providers": [
          {
            "Name": "OpenRouter",
            "ModelName": "qwen/qwen3-0.6b-04-28:free",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.0,
              "CompletionPerMillion": 0.0
            },
            "Tags": ["free", "reasoning", "thinking", "lightweight", "ultra-fast", "multilingual", "openai-compatible", "aggregator"]
          }
        ]
      }
    ]
  },
  "ProviderRegistry": {
    "OpenAI": {
      "EndpointUrl": "https://api.openai.com/v1",
      "ApiKeyEnvironmentVariable": "OPENAI_API_KEY",
      "Compatibility": "OpenAI",
      "Headers": null,
      "Timeout": "00:01:00",
      "MaxRetries": 3,
      "Description": "Official OpenAI API endpoint"
    },
    "Anthropic": {
      "EndpointUrl": "https://api.anthropic.com",
      "ApiKeyEnvironmentVariable": "ANTHROPIC_API_KEY", 
      "Compatibility": "Anthropic",
      "Headers": {
        "anthropic-version": "2023-06-01"
      },
      "Timeout": "00:02:00",
      "MaxRetries": 3,
      "Description": "Official Anthropic API endpoint"
    },
    "OpenRouter": {
      "EndpointUrl": "https://openrouter.ai/api/v1",
      "ApiKeyEnvironmentVariable": "OPENROUTER_API_KEY",
      "Compatibility": "OpenAI",
      "Headers": {
        "HTTP-Referer": "https://github.com/your-org/lm-dotnet-tools",
        "X-Title": "LMConfig Application"
      },
      "Timeout": "00:02:00", 
      "MaxRetries": 3,
      "Description": "OpenRouter aggregator with multiple provider fallback"
    },
    "DeepInfra": {
      "EndpointUrl": "https://api.deepinfra.com/v1/openai",
      "ApiKeyEnvironmentVariable": "DEEPINFRA_API_KEY",
      "Compatibility": "OpenAI",
      "Headers": null,
      "Timeout": "00:01:30",
      "MaxRetries": 3,
      "Description": "DeepInfra multi-vendor model hosting"
    },
    "Groq": {
      "EndpointUrl": "https://api.groq.com/openai/v1", 
      "ApiKeyEnvironmentVariable": "GROQ_API_KEY",
      "Compatibility": "OpenAI",
      "Headers": null,
      "Timeout": "00:00:30",
      "MaxRetries": 2,
      "Description": "Groq ultra-fast inference platform"
    },
    "Cerebras": {
      "EndpointUrl": "https://api.cerebras.ai/v1",
      "ApiKeyEnvironmentVariable": "CEREBRAS_API_KEY", 
      "Compatibility": "OpenAI",
      "Headers": null,
      "Timeout": "00:00:45",
      "MaxRetries": 2,
      "Description": "Cerebras high-performance inference"
    },
    "GoogleGemini": {
      "EndpointUrl": "https://generativelanguage.googleapis.com/v1beta/openai",
      "ApiKeyEnvironmentVariable": "GEMINI_API_KEY",
      "Compatibility": "OpenAI", 
      "Headers": null,
      "Timeout": "00:01:30",
      "MaxRetries": 3,
      "Description": "Google Gemini via OpenAI-compatible API"
    }
  }
} 