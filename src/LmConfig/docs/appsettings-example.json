{
  "AppConfig": {
    "Models": [
      {
        "Id": "claude-3-sonnet",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "Anthropic",
            "supports_budget_tokens": true,
            "supports_thinking_type": true,
            "max_thinking_tokens": 8192,
            "is_built_in": false,
            "is_exposed": true,
            "parameter_name": "thinking"
          },
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 5242880,
            "max_images_per_message": 20
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": false,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 200000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 190000
          },
          "response_formats": {
            "supports_json_mode": false,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["thinking", "multimodal", "function-calling", "long-context"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:15",
            "tokens_per_second": 50.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Anthropic",
            "ModelName": "claude-3-sonnet-20240229",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 3.0,
              "CompletionPerMillion": 15.0
            },
            "Tags": ["high-quality", "thinking", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "anthropic/claude-3-sonnet",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 3.0,
              "CompletionPerMillion": 15.0
            },
            "SubProviders": [
              {
                "Name": "Anthropic",
                "ModelName": "claude-3-sonnet-20240229",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 3.0,
                  "CompletionPerMillion": 15.0
                }
              },
              {
                "Name": "AWS Bedrock",
                "ModelName": "anthropic.claude-3-sonnet-20240229-v1:0",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 3.0,
                  "CompletionPerMillion": 15.0
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "gpt-4o",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": true,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "supported_audio_formats": ["mp3", "wav", "m4a"],
            "max_image_size": 20971520,
            "max_images_per_message": 10
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 128,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 16384,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "structured-output"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:10",
            "tokens_per_second": 75.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "gpt-4o",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 2.5,
              "CompletionPerMillion": 10.0
            },
            "Tags": ["fast", "high-quality", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "openai/gpt-4o",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 2.5,
              "CompletionPerMillion": 10.0
            },
            "SubProviders": [
              {
                "Name": "OpenAI",
                "ModelName": "gpt-4o",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 2.5,
                  "CompletionPerMillion": 10.0
                }
              },
              {
                "Name": "Azure OpenAI",
                "ModelName": "gpt-4o",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 2.5,
                  "CompletionPerMillion": 10.0
                }
              },
              {
                "Name": "Together AI",
                "ModelName": "meta-llama/Llama-2-70b-chat-hf",
                "Priority": 3,
                "Pricing": {
                  "PromptPerMillion": 2.2,
                  "CompletionPerMillion": 9.5
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "openai/gpt-4o",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 2.2,
              "CompletionPerMillion": 9.0
            },
            "Tags": ["economic", "openai-compatible", "multi-vendor"]
          }
        ]
      },
      {
        "Id": "gpt-4o-mini",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": false,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "max_image_size": 20971520,
            "max_images_per_message": 10
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 128,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 16384,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "structured-output"],
          "performance": {
            "typical_latency": "00:00:01",
            "max_latency": "00:00:05",
            "tokens_per_second": 100.0,
            "quality_tier": "medium",
            "cost_tier": "economy"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "gpt-4o-mini",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 0.15,
              "CompletionPerMillion": 0.6
            },
            "Tags": ["fast", "economic", "multimodal"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "openai/gpt-4o-mini",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.15,
              "CompletionPerMillion": 0.6
            },
            "Tags": ["fallback", "economic", "reliable", "aggregator", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "openai/gpt-4o-mini",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.12,
              "CompletionPerMillion": 0.5
            },
            "Tags": ["economic", "cost-effective", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "o1-preview",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "OpenAI",
            "supports_budget_tokens": false,
            "supports_thinking_type": false,
            "is_built_in": true,
            "is_exposed": false
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 32768,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": false,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": false,
          "supported_features": ["reasoning", "complex-problem-solving"],
          "performance": {
            "typical_latency": "00:00:15",
            "max_latency": "00:01:00",
            "tokens_per_second": 10.0,
            "quality_tier": "premium"
          }
        },
        "Providers": [
          {
            "Name": "OpenAI",
            "ModelName": "o1-preview",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 15.0,
              "CompletionPerMillion": 60.0
            },
            "Tags": ["reasoning", "premium", "complex-tasks"]
          }
        ]
      },
      {
        "Id": "llama-3.1-70b-instruct",
        "IsReasoning": false,
        "Capabilities": {
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 4096,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["function-calling", "open-source"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:08",
            "tokens_per_second": 80.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "llama3-70b-8192",
            "Priority": 3,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "Tags": ["ultra-fast", "high-performance", "open-source", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "meta-llama/Meta-Llama-3.1-70B-Instruct",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.52,
              "CompletionPerMillion": 0.75
            },
            "Tags": ["economic", "open-source", "openai-compatible", "multi-vendor"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "meta-llama/llama-3.1-70b-instruct",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "SubProviders": [
              {
                "Name": "Together AI",
                "ModelName": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 0.59,
                  "CompletionPerMillion": 0.79
                }
              },
              {
                "Name": "Fireworks AI",
                "ModelName": "accounts/fireworks/models/llama-v3p1-70b-instruct",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 0.54,
                  "CompletionPerMillion": 0.74
                }
              },
              {
                "Name": "Perplexity",
                "ModelName": "llama-3.1-70b-instruct",
                "Priority": 3,
                "Pricing": {
                  "PromptPerMillion": 0.52,
                  "CompletionPerMillion": 0.75
                }
              },
              {
                "Name": "Lepton AI",
                "ModelName": "llama3-1-70b",
                "Priority": 4,
                "Pricing": {
                  "PromptPerMillion": 0.50,
                  "CompletionPerMillion": 0.70
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "open-source", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "llama-4-scout-17b-16e-instruct",
        "IsReasoning": false,
        "Capabilities": {
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 131072,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["function-calling", "open-source"],
          "performance": {
            "typical_latency": "00:00:01",
            "max_latency": "00:00:05",
            "tokens_per_second": 120.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "meta-llama/llama-4-scout-17b-16e-instruct",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.2,
              "CompletionPerMillion": 0.2
            },
            "Tags": ["ultra-fast", "economic", "high-performance", "open-source", "openai-compatible"]
          },
          {
            "Name": "Cerebras",
            "ModelName": "llama-4-scout-17b-16e-instruct",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.1,
              "CompletionPerMillion": 0.1
            },
            "Tags": ["ultra-fast", "economic", "high-performance", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "gemini-2.0-flash",
        "IsReasoning": false,
        "Capabilities": {
          "multimodal": {
            "supports_images": true,
            "supports_audio": true,
            "supports_video": false,
            "supported_image_formats": ["jpeg", "png", "webp", "gif"],
            "supported_audio_formats": ["mp3", "wav", "m4a"],
            "max_image_size": 20971520,
            "max_images_per_message": 16
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 64,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 1000000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 990000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": true,
            "supports_json_schema": true
          },
          "supports_streaming": true,
          "supported_features": ["multimodal", "function-calling", "long-context", "structured-output"],
          "performance": {
            "typical_latency": "00:00:02",
            "max_latency": "00:00:08",
            "tokens_per_second": 85.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "GoogleGemini",
            "ModelName": "gemini-2.0-flash",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.075,
              "CompletionPerMillion": 0.3
            },
            "Tags": ["economic", "multimodal", "fast", "long-context", "openai-compatible"]
          },
          {
            "Name": "OpenRouter",
            "ModelName": "google/gemini-2.0-flash",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.075,
              "CompletionPerMillion": 0.3
            },
            "SubProviders": [
              {
                "Name": "Google AI",
                "ModelName": "gemini-2.0-flash",
                "Priority": 1,
                "Pricing": {
                  "PromptPerMillion": 0.075,
                  "CompletionPerMillion": 0.3
                }
              },
              {
                "Name": "Google Vertex AI",
                "ModelName": "gemini-2.0-flash",
                "Priority": 2,
                "Pricing": {
                  "PromptPerMillion": 0.075,
                  "CompletionPerMillion": 0.3
                }
              }
            ],
            "Tags": ["fallback", "reliable", "aggregator", "multimodal", "openai-compatible"]
          }
        ]
      },
      {
        "Id": "deepseek-r1-distill-llama-70b",
        "IsReasoning": true,
        "Capabilities": {
          "thinking": {
            "type": "DeepSeek",
            "supports_budget_tokens": false,
            "supports_thinking_type": false,
            "is_built_in": true,
            "is_exposed": true
          },
          "function_calling": {
            "supports_tools": true,
            "supports_parallel_calls": true,
            "supports_tool_choice": true,
            "max_tools_per_request": 32,
            "supported_tool_types": ["function"]
          },
          "token_limits": {
            "max_context_tokens": 128000,
            "max_output_tokens": 8192,
            "recommended_max_prompt_tokens": 120000
          },
          "response_formats": {
            "supports_json_mode": true,
            "supports_structured_output": false,
            "supports_json_schema": false
          },
          "supports_streaming": true,
          "supported_features": ["reasoning", "function-calling"],
          "performance": {
            "typical_latency": "00:00:03",
            "max_latency": "00:00:12",
            "tokens_per_second": 60.0,
            "quality_tier": "high"
          }
        },
        "Providers": [
          {
            "Name": "Groq",
            "ModelName": "deepseek-r1-distill-llama-70b",
            "Priority": 2,
            "Pricing": {
              "PromptPerMillion": 0.59,
              "CompletionPerMillion": 0.79
            },
            "Tags": ["ultra-fast", "reasoning", "thinking", "high-performance", "openai-compatible"]
          },
          {
            "Name": "DeepInfra",
            "ModelName": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
            "Priority": 1,
            "Pricing": {
              "PromptPerMillion": 0.52,
              "CompletionPerMillion": 0.75
            },
            "Tags": ["economic", "reasoning", "thinking", "openai-compatible", "multi-vendor"]
          }
        ]
      }
    ]
  }
} 