# LmStreaming.Sample Environment Configuration
# Copy this file to .env and fill in your values.
# .env files are git-ignored and will not be committed.

# Provider mode: "test" (default), "openai", or "anthropic"
LM_PROVIDER_MODE=test

# OpenAI / OpenAI-compatible provider settings
# Used when LM_PROVIDER_MODE=openai
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o

# Anthropic / Anthropic-compatible provider settings
# Used when LM_PROVIDER_MODE=anthropic
# NOTE: ANTHROPIC_BASE_URL should include the full API path prefix.
# The client appends /messages to this URL directly.
# For Anthropic: https://api.anthropic.com/v1 (default)
# For Kimi: https://api.kimi.com/coding
ANTHROPIC_API_KEY=
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Example: Kimi 2.5 via OpenAI-compatible API
# LM_PROVIDER_MODE=openai
# OPENAI_API_KEY=your-kimi-key
# OPENAI_BASE_URL=https://api.moonshot.cn/v1
# OPENAI_MODEL=kimi-2.5

# Example: Kimi 2.5 via Anthropic-compatible API
# LM_PROVIDER_MODE=anthropic
# ANTHROPIC_API_KEY=your-kimi-key
# ANTHROPIC_BASE_URL=https://api.kimi.com/coding
# ANTHROPIC_MODEL=kimi-2.5
